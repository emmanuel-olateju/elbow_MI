Stuyd Description:
    This study make use of the same transformer hyperparameter configuration of the EEGConformer model, 
    replacing the CNN backbone with one that preserves the TF representation of each channel. The TF 
    representation of each channel are then stacked across the frequency axis as embedding for each 
    time-point for processing by the transformer. This is tested on multiple datasets: BNCI2014_001, 
    BNCI2014_004, Zhou2016 and more to be tested on.

Exp_0.1: Within-Subject Cross-Validation
    In this experiment, we make use of five-fold stratified cross-validation, training a model for each subject.

Exp_0.2: Withing-Subject Train/Test (Cross-Validation) & Hold-Out validation Split
    In this experiment, we make use of a hold-out validation split, training the remaining set (Train/test) 
    through cross validation.

Exp_0.3: LOSO Validation
    As a first step towards transfer learning, we evaluate the performance of the Multichannel TF-Conformer
    in LOSO validation.

Exp_1.1: Channels_Frequency Attention parameter
    Test effect of learnable channels-Frequency Attention Paramter on Within-Subject Cross-Validation from 
    Exp_0.1

Exp_2.1: Cross-Subject Pre-Training
    We employ a pre-training subset (70% of total subjects data) using the same splitting strategy as in 
    Exp_0.2. 
    
Exp_2.2: Within-Subject Fine-tuning, Fixed Learning Rate
    Then we fine-tune the pre-trained model from Exp_2.1 for 60% of each subject data independently using the same 
    learning rate as during pre-training , and testing on the remaining 40%. 

Exp_2.3: Within-Subject Fine-tuning, Depth Decreasing Learning Rate
    We make use of the pre-trained models and same training splits from Exp_2.1, the  fine-tun on each subject 
    independently decreasing learning rate as we progress in each layer.

Exp_2.4: Within-Subject Fine-tuning, Depth Increasing Learning Rate
    We make use of the pre-trained models and same training splits from Exp_2.1, the  fine-tun on each subject 
    independently increasing learning rate as we progress in each layer.

Exp_2.?: Improve Within-Subjet Fine-tuning
    Develop a method to improve within-subject fine-tuning not necssariyl SOTA level performance, but close to an 
    extent is okay.

Exp_2.*: Cross-Subject Pre-Training, Cross-Subject Fine-tuning
    We employ the same pre-trained model, data split from Exp_2.1, and best learning rate strategy but fine-tune on 70% 
    of all subjects data left-out during pre-training. 

Exp 2.4: representational Alignment Analysis